{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from time import time\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.max_colwidth', 65)  # default: 50\n",
    "\n",
    "train = pd.read_csv(\"train_preprocessed.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this nb we'll play around with positive examples, trying to infer the possible types of questions available. \n",
    "\n",
    "First, let's drop all the negative examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'qid1', 'qid2', 'question1', 'question2',\n",
       "       'is_duplicate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in share market in i...</td>\n",
       "      <td>what is the step by step guide to invest in share market?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor (koh-i-noor) diamond?</td>\n",
       "      <td>what would happen if the indian government stole the kohinoor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet connection while ...</td>\n",
       "      <td>how can internet speed be increased by hacking through dns?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar, salt, methane and c...</td>\n",
       "      <td>which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>astrology: i am a capricorn sun cap moon and cap rising...wha...</td>\n",
       "      <td>i'm a triple capricorn (sun, moon and ascendant in capricorn)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id  qid1  qid2  \\\n",
       "0           0   0     1     2   \n",
       "1           1   1     3     4   \n",
       "2           2   2     5     6   \n",
       "3           4   4     9    10   \n",
       "4           5   5    11    12   \n",
       "\n",
       "                                                          question1  \\\n",
       "0  what is the step by step guide to invest in share market in i...   \n",
       "1               what is the story of kohinoor (koh-i-noor) diamond?   \n",
       "2  how can i increase the speed of my internet connection while ...   \n",
       "3  which one dissolve in water quikly sugar, salt, methane and c...   \n",
       "4  astrology: i am a capricorn sun cap moon and cap rising...wha...   \n",
       "\n",
       "                                                          question2  \\\n",
       "0         what is the step by step guide to invest in share market?   \n",
       "1  what would happen if the indian government stole the kohinoor...   \n",
       "2       how can internet speed be increased by hacking through dns?   \n",
       "3                           which fish would survive in salt water?   \n",
       "4  i'm a triple capricorn (sun, moon and ascendant in capricorn)...   \n",
       "\n",
       "   is_duplicate  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.loc[ train.is_duplicate == 1 , lambda df: ['question1', 'question2'] ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We'll now change the questions to be lists of words, and remove all words below some frequency. This should leave only the interesting words (the correct thing to do is probably use them as well as word2vec, so that some of the meaning remains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_lst_iterator1 = itertools.chain(*[''.join(map(lambda x: x if str.isalnum(x) else ' ', q)).split() for q in train.question1])\n",
    "words_lst_iterator2 = itertools.chain(*[''.join(map(lambda x: x if str.isalnum(x) else ' ', q)).split() for q in train.question2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "word_counter = Counter(itertools.chain(words_lst_iterator1, words_lst_iterator2))\n",
    "words = sorted(word_counter.keys(), key = lambda x: word_counter[x], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q_words = [p[0] for p in word_counter.most_common()[:59]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2825"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter[\"than\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the', 'what', 'is', 'how', 'i', 'to', 'do', 'in', 'a', 'are', 'of', 'can', 'and', 'you', 'best', 'why', 'for', 'my', 'on', 'it', 'which', 'be', 'some', 'does', 'your', 'get', 'if', 's', 'india', 'should', 'that', 'will', 'quora', 'have', 'or', 'with', 'people', 'from', 'an', 'who', 'money', 'way', 'would', 'life', 'good', 'about', 'there', 'make', 'most', 'trump', 'we', 'learn', 'when', 'one', 'like', 'did', 'as', 'between', '500']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pprint\n",
    "q_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_in_qwords(w, q_words = q_words):\n",
    "    if w in q_words:\n",
    "        return w\n",
    "    else:\n",
    "        return \"*\"\n",
    "    \n",
    "def jokerize_question(question):\n",
    "    q = (''.join(map(lambda x: x if str.isalnum(x) else ' ', question))).split()\n",
    "    q = list(map( word_in_qwords, q))\n",
    "    l = []\n",
    "    for i in range(len(q)-1):\n",
    "        if q[i] == q[i+1] == '*':\n",
    "            continue\n",
    "        else:\n",
    "            l.append(q[i])\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question1', 'question2'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pped_data = train.applymap(jokerize_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[*, i, *, a, *, and, *, what, does, that, *, about]</td>\n",
       "      <td>[i, *, a, *, and, *, in, *, what, does, *, about]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[how, can, i, be, a, good]</td>\n",
       "      <td>[what, should, i, do, to, be, a]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[how, do, i, *, and, *, my]</td>\n",
       "      <td>[how, can, i, *, my]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[what, can, make, *, to]</td>\n",
       "      <td>[how, can, you, make, *, to]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[what, *, your, *]</td>\n",
       "      <td>[what, *, your]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question1  \\\n",
       "4   [*, i, *, a, *, and, *, what, does, that, *, about]   \n",
       "6                            [how, can, i, be, a, good]   \n",
       "9                           [how, do, i, *, and, *, my]   \n",
       "10                             [what, can, make, *, to]   \n",
       "11                                   [what, *, your, *]   \n",
       "\n",
       "                                            question2  \n",
       "4   [i, *, a, *, and, *, in, *, what, does, *, about]  \n",
       "6                    [what, should, i, do, to, be, a]  \n",
       "9                                [how, can, i, *, my]  \n",
       "10                       [how, can, you, make, *, to]  \n",
       "11                                    [what, *, your]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pped_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q_words.append('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_to_freq = {q_words[i]: i for i in range(len(q_words))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pped_data = pped_data.applymap(lambda l: list(map(lambda w: word_to_freq[w], l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The training data, to our lstm model. Each pair of questions starting on even indices will correspond to duplicate questions.\n",
    "X = [None]*(len(pped_data))*2\n",
    "X[::2] = pped_data['question1'].tolist()\n",
    "X[1::2] = pped_data['question2'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(map(len, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(x)>25 for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292962"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = sequence.pad_sequences(X, maxlen=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 59,  4, 59,  8,\n",
       "       59, 12, 59,  1, 23, 30, 59, 45])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 5)           300       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 5)                 220       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                120       \n",
      "=================================================================\n",
      "Total params: 640.0\n",
      "Trainable params: 640\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(q_words), 5))\n",
    "model.add(LSTM(5))\n",
    "model.add(Dense(output_len,activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this model is to take a sentence as an input, and return a probability estimate of what \"category\" the sentence lies in. We have `output_len` number of possible categories, and the model ends with a softmax layer to make sure that we get probabilities. \n",
    "\n",
    "If we know the number of categories we want, and their distribution (i.e. in what probability each data point will be assigned to any specific category), we can try and enforce two things:\n",
    "1. Make the probability of a pair of duplicate questions to be in a similar category as high as possible.\n",
    "2. Make the distribution of the categories close to the given apriori distribution.\n",
    "\n",
    "(Later we will try to give other solutions, since the distribution of categories is not known...)\n",
    "\n",
    "We will do that by composing the loss from the sum of two values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_loss(y_true, y_pred, gamma=1):\n",
    "    # We do not need y_true. \n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    # Motivate duplicate question to go together:\n",
    "    loss += cluster_duplicates(y_pred)\n",
    "    \n",
    "    # Motivate a proper distribution of categories\n",
    "    loss += gamma*distribute_cats(y_pred)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `cluster_duplicates` returns the part of the loss responsible for enforcing high probability of duplicate questions having the same category. \n",
    "\n",
    "Let $x,x'$ be two questions, and let $M$ be the model we are training. We think of $M(x)_i$ as the probability of $x$ belonging to category $i$ (note that $x$ can only be in one category at a time). The \"probability\" of $x$ and $x'$ having the same category is thus $\\sum_i M(x)_i M(x')_i = \\langle M(x), M(x') \\rangle$. Hence we return the sum of logarithms of the scalar product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_duplicates(y): # In this method we return the sum of log probabilities of the duplicate questions having the same category.\n",
    "    y_pairs = K.reshape(y, [-1, output_len, 2])    \n",
    "    y_first = K.reshape( K.slice(y_pairs, [0,0,0], [-1,-1,1]), [-1, output_len, 1])\n",
    "    y_second= K.reshape( K.slice(y_pairs, [0,0,1], [-1,-1,1]), [-1, output_len, 1])\n",
    "    return K.sum( K.log( K.dot(y_first, K.transpose(y_second) ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also minimize the KL divergence of the apriori distribution of categories from what we'll get. \n",
    "\n",
    "The first distribution we'll try out is by choosing each probability uniformly. (intuitively this should not be the case, and we would prefer some kind of harmonic descending sequence, but I think my intuition does not worth much..) \n",
    "Eventually we'd not want to fix a strict distribution but instead try and enforce some rules for the distribution. However all simple ideas I had so far do not converge well, so we shall try this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_temp = [np.random.rand() for _ in range(output_len) ]\n",
    "s_temp = sum(l_temp)\n",
    "l_temp = [p_temp / s_temp for p_temp in l_temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniformly_random_distribution = np.array(l_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-33-0fd1a9920f1a>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-33-0fd1a9920f1a>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    K.sum(axis=)\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def distribute_cats(y):\n",
    "    K.sum(axis=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = K.constant([[1,2,2],[3,4,4]])\n",
    "K.sum(y,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_model = Sequential()\n",
    "test_model.add( Lambda( lambda x: K.sum(x, axis=0), input_shape=(2,3), output_shape = (3,)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.,   8.,  10.],\n",
       "       [ 12.,  14.,  16.]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.reshape(np.arange(12), (2,2,3))\n",
    "test_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2],\n",
       "        [ 3,  4,  5]],\n",
       "\n",
       "       [[ 6,  7,  8],\n",
       "        [ 9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14],\n",
       "        [15, 16, 17]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfKernel",
   "language": "python",
   "name": "tfkernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
